
---

# üìå Proyecto de Monitoreo en ML - IA con TinyBERT, BERT-Mini y DistilBERT con MLflow

Este proyecto implementa un modelo de clasificaci√≥n de texto utilizando **TinyBERT**, **BERT-Mini** y **DistilBERT**, con seguimiento completo de m√©tricas y visualizaciones mediante **MLflow**.

---

## üìñ Introducci√≥n

Este proyecto utiliza modelos de la familia BERT para clasificar textos del dataset **AG News** en cuatro categor√≠as. Durante el entrenamiento, se monitorea el rendimiento mediante m√©tricas clave como **accuracy, F1-score, precision y recall**, adem√°s de generar visualizaciones para facilitar el an√°lisis de resultados.

El objetivo es comparar el rendimiento de estos modelos y determinar cu√°l ofrece la mejor precisi√≥n y generalizaci√≥n.

---

## üéØ Justificaci√≥n

La clasificaci√≥n de texto es esencial en aplicaciones como la organizaci√≥n autom√°tica de noticias. Se ha elegido **AG News** por su relevancia y tama√±o, mientras que los modelos de la familia **BERT** permiten balancear rendimiento y eficiencia computacional. **MLflow** facilita el monitoreo del entrenamiento y la visualizaci√≥n de m√©tricas para detectar problemas como el sobreajuste.

---

## üéØ Objetivos

1Ô∏è‚É£ **Entrenar** y comparar **TinyBERT**, **BERT-Mini** y **DistilBERT** en la tarea de clasificaci√≥n de texto.  

2Ô∏è‚É£ **Monitorear** el entrenamiento mediante gr√°ficas de la funci√≥n de costo y m√©tricas de desempe√±o.  

3Ô∏è‚É£ **Evaluar** el rendimiento de cada modelo con m√©tricas espec√≠ficas.  

4Ô∏è‚É£ **Utilizar MLflow** para registrar y visualizar los resultados del experimento.  

5Ô∏è‚É£ **Presentar un an√°lisis comparativo** de los modelos.  

---

## üìÇ Dataset: AG News

El dataset **AG News** contiene noticias categorizadas en cuatro clases:

- üåç **Mundo** (Clase 0)
- üèÜ **Deportes** (Clase 1)
- üí∞ **Negocios** (Clase 2)
- üî¨ **Ciencia/Tecnolog√≠a** (Clase 3)

Cada instancia consta de un t√≠tulo y una descripci√≥n de la noticia, junto con su etiqueta correspondiente. Se ha reducido el tama√±o a **1000 muestras para entrenamiento** y **500 para test**.

---

## ü§ñ Modelos

Se entrenaron y compararon los siguientes modelos:

- **TinyBERT** üèãÔ∏è‚Äç‚ôÇÔ∏è: Versi√≥n compacta y eficiente de BERT.

- **BERT-Mini** üìè: Un modelo con una estructura reducida de BERT.

- **DistilBERT** üöÄ: Modelo liviano que retiene el 97% del rendimiento de BERT con solo el 60% de los par√°metros.

---
## MLflow desde local

1Ô∏è‚É£ **Metricas del Modelo 1**

![pantallazo1](Proyecto_ml/images/pantallazo1.png)


2Ô∏è‚É£ **Metricas del Modelo 2**

![pantallazo2](Proyecto_ml/images/pantallazo2.png)


3Ô∏è‚É£ **Metricas del Modelo 3**

![pantallazo3](Proyecto_ml/images/pantallazo3.png)


4Ô∏è‚É£ **Metricas del Modelo 4**

![pantallazo4](Proyecto_ml/images/pantallazo4.png)


5Ô∏è‚É£ **Overview**

![pantallazo5](Proyecto_ml/images/pantallazo5.png)


6Ô∏è‚É£ **Artifacts**

![pantallazo6](Proyecto_ml/images/pantallazo6.png)

---

## üìä An√°lisis de Cada Modelo

### **TinyBERT**
#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy TinyBERT](Proyecto_ml/graficas/tinybert_accuracy_evolution.png)
- **Crecimiento progresivo de accuracy**, comenzando en **0.715** y alcanzando **0.825**.
- Aunque mejora con las √©pocas, **su rendimiento es inferior a los otros modelos**, indicando menor capacidad de aprendizaje.
- La tendencia de crecimiento indica que a√∫n podr√≠a mejorar con m√°s entrenamiento, pero el ritmo de crecimiento sugiere que podr√≠a estancarse pronto.

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n TinyBERT](Proyecto_ml/graficas/tinybert_confusion_matrix.png)
- **Mayor confusi√≥n en las categor√≠as Business y Sci/Tech**, lo que indica que el modelo **tiene dificultades en separar noticias de negocios y tecnolog√≠a**.
- Predicciones m√°s err√≥neas en comparaci√≥n con los otros modelos.
- La clasificaci√≥n de la categor√≠a ‚ÄúMundo‚Äù es m√°s precisa que otras, lo que sugiere que el modelo diferencia mejor eventos globales que temas t√©cnicos.

#### **Evoluci√≥n de F1-Score**
![F1-Score TinyBERT](Proyecto_ml/graficas/tinybert_f1_evolution.png)
- **F1-score final de 0.8247**, reflejando que el modelo **no logra un balance √≥ptimo entre precisi√≥n y recall**.
- **La diferencia entre accuracy y F1-score indica que el modelo tiende a predecir algunas categor√≠as con mayor confianza que otras**, pero sigue teniendo errores significativos en ciertos segmentos del dataset.


#### **Funci√≥n de Costo**
![P√©rdida TinyBERT](Proyecto_ml/graficas/tinybert_loss_function.png)
- **P√©rdida inicial m√°s alta** y reducci√≥n m√°s lenta, lo que sugiere que **requiere m√°s entrenamiento para converger**.
- Puede haber indicios de sobreajuste si se entrena demasiado sin mejorar sustancialmente el desempe√±o.
- **La funci√≥n de costo no se estabiliza completamente**, lo que indica que el modelo sigue ajustando par√°metros sin alcanzar una convergencia clara.

---

### **BERT-Mini**
#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy BERT-Mini](Proyecto_ml/graficas/bert_mini_accuracy_evolution.png)
-- **Accuracy final de 0.832**, lo que representa una mejora constante durante las √©pocas de entrenamiento.
- Su crecimiento es m√°s estable que TinyBERT, pero no alcanza la precisi√≥n lograda por DistilBERT.
- La tendencia sugiere que el modelo podr√≠a beneficiarse de m√°s √©pocas de entrenamiento para lograr un mayor ajuste sin caer en sobreajuste.

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n BERT-Mini](Proyecto_ml/graficas/bert_mini_confusion_matrix.png)
- **Menos confusi√≥n** que TinyBERT, lo que indica una mejor separaci√≥n de clases.
- Sigue mostrando errores en la clasificaci√≥n de noticias de **Negocios** y **Ciencia/Tecnolog√≠a**, lo que sugiere que los t√©rminos utilizados en estos dominios pueden ser similares y confundir al modelo.
- Se observa una leve mejora en la correcta clasificaci√≥n de la categor√≠a **Mundo**, donde hay menos errores que en TinyBERT.

#### **Evoluci√≥n de F1-Score**
![F1-Score BERT-Mini](Proyecto_ml/graficas/bert_mini_f1_evolution.png)
- **F1-score final de 0.8311**, mostrando un equilibrio entre precisi√≥n y recall.
- Su crecimiento es consistente y m√°s estable que en TinyBERT, lo que sugiere que generaliza mejor.
- Aunque es mejor que TinyBERT, a√∫n tiene margen de mejora, ya que no logra igualar el rendimiento de DistilBERT.

#### **Funci√≥n de Costo**
![P√©rdida BERT-Mini](Proyecto_ml/graficas/bert_mini_loss_function.png)
- **Reducci√≥n de p√©rdida m√°s r√°pida** en comparaci√≥n con TinyBERT, lo que indica que el modelo se ajusta m√°s eficientemente.
- Se observa una tendencia de convergencia m√°s clara, aunque podr√≠a beneficiarse de ajustes en la tasa de aprendizaje para optimizar a√∫n m√°s su desempe√±o.

---

### **DistilBERT**
#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy DistilBERT](Proyecto_ml/graficas/distilbert_accuracy_evolution.png)
- **Accuracy final de 0.866**, la m√°s alta de los tres modelos, lo que indica un mejor rendimiento general.
- La curva de aprendizaje muestra una estabilidad clara desde la primera √©poca, lo que sugiere que el modelo converge m√°s r√°pido y con menor necesidad de ajustes.
- Su alto desempe√±o sugiere que captura mejor las relaciones entre palabras dentro del dataset AG News.

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n DistilBERT](Proyecto_ml/graficas/distilbert_confusion_matrix.png)
- **Menor confusi√≥n general**, mostrando una clara mejora en la diferenciaci√≥n de clases.
- Aunque sigue habiendo algunos errores en la clasificaci√≥n de Negocios y Ciencia/Tecnolog√≠a, estos son considerablemente menores que en los otros modelos.
- Su precisi√≥n en todas las categor√≠as es m√°s alta, con una reducci√≥n notable en los falsos positivos y falsos negativos.


#### **Evoluci√≥n de F1-Score**
![F1-Score DistilBERT](Proyecto_ml/graficas/distilbert_f1_evolution.png)
- **F1-score de 0.8653**, lo que muestra que DistilBERT tiene el mejor balance entre precisi√≥n y recall.
- Su curva de mejora es m√°s r√°pida que la de los otros modelos, lo que indica que aprende de manera m√°s eficiente desde las primeras √©pocas.

#### **Funci√≥n de Costo**
![P√©rdida DistilBERT](Proyecto_ml/graficas/distilbert_loss_function.png)
- **Menor p√©rdida final** y mejor convergencia en comparaci√≥n con los otros modelos.
- Se observa una reducci√≥n r√°pida y estable de la funci√≥n de costo, lo que sugiere que el modelo encuentra un √≥ptimo m√°s eficientemente.
- No se observan indicios de sobreajuste, lo que indica que DistilBERT es capaz de generalizar mejor en los datos de prueba.

---

## üìä Comparaci√≥n de Modelos

### **Comparaci√≥n de Accuracy entre Modelos**
![Comparaci√≥n de Accuracy](Proyecto_ml/graficas/comparison_accuracy.png)
 **DistilBERT lidera con 0.866, mientras que TinyBERT queda en √∫ltimo lugar con 0.826**.
- **BERT-Mini se encuentra en un punto intermedio, con 0.832**, lo que muestra que tiene un desempe√±o aceptable pero no alcanza el nivel de DistilBERT.

### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy](Proyecto_ml/graficas/comparison_accuracy_evolution.png)
- **DistilBERT tiene una curva de aprendizaje m√°s estable y r√°pida**.
- **TinyBERT muestra la curva de mejora m√°s lenta**, lo que sugiere que necesita m√°s entrenamiento para alcanzar un rendimiento competitivo.

### **Comparaci√≥n de Todas las M√©tricas**
![Comparaci√≥n de M√©tricas](Proyecto_ml/graficas/comparison_all_metrics.png)
- DistilBERT lidera en **accuracy, precision, recall y F1-score**.
- **TinyBERT es el modelo con menor recall**, indicando que tiene m√°s dificultades en identificar correctamente todas las categor√≠as.

### **Comparaci√≥n de F1-Score**
![Comparaci√≥n de F1-Score](Proyecto_ml/graficas/comparison_f1.png)
- **DistilBERT mantiene el mejor F1-score, asegurando un equilibrio √≥ptimo en clasificaci√≥n**.
- **La diferencia entre los modelos indica que TinyBERT es el m√°s d√©bil en t√©rminos de balance entre precisi√≥n y recall**.

### **Gr√°fico Radar ‚Äì Comparaci√≥n Completa**
![Gr√°fico Radar](Proyecto_ml/graficas/comparison_radar.png)
- **DistilBERT domina todas las m√©tricas** y es el modelo m√°s eficiente.
- **TinyBERT tiene las puntuaciones m√°s bajas en todas las m√©tricas evaluadas**.

---

## üèÜ **Conclusi√≥n Final**

1Ô∏è‚É£ **DistilBERT es el mejor modelo**, con **mayor precisi√≥n y menor confusi√≥n**.

2Ô∏è‚É£ **BERT-Mini es una alternativa intermedia**, con **buen rendimiento pero inferior a DistilBERT**.

3Ô∏è‚É£ **TinyBERT es el menos eficiente**, con **m√°s errores de clasificaci√≥n y menor precisi√≥n**.

4Ô∏è‚É£ **Los tres modelos muestran dificultades similares en diferenciar noticias de negocios y tecnolog√≠a**, sugiriendo que se podr√≠an mejorar los embeddings o el ajuste fino del dataset.

---

## ‚ö†Ô∏è Limitaciones

‚ö†Ô∏è Uso de un dataset reducido para optimizar tiempos de entrenamiento.
‚ö†Ô∏è Algunas clases pueden requerir mayor ajuste en hiperpar√°metros.
‚ö†Ô∏è Para grandes modelos, puede requerirse **m√°s recursos computacionales**.

---


