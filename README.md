# ğŸ“Œ Proyecto de Monitoreo en ML - IA con TinyBERT y MLflow

Este proyecto implementa un modelo de clasificaciÃ³n de texto utilizando **TinyBERT**, con seguimiento completo de mÃ©tricas y visualizaciones mediante **MLflow**.

---

## ğŸ“– IntroducciÃ³n

Este proyecto utiliza **TinyBERT** para clasificar textos del dataset **AG News** en cuatro categorÃ­as. Durante el entrenamiento, se monitorea el rendimiento mediante mÃ©tricas clave como **accuracy, F1-score, precision y recall**, ademÃ¡s de generar visualizaciones para facilitar el anÃ¡lisis de resultados.

El objetivo es demostrar cÃ³mo entrenar, evaluar y monitorear un modelo de **Machine Learning** en un entorno realista.

---

## ğŸ¯ JustificaciÃ³n

La clasificaciÃ³n de texto es esencial en aplicaciones como la organizaciÃ³n automÃ¡tica de noticias. Se ha elegido **AG News** por su relevancia y tamaÃ±o, mientras que **TinyBERT** permite un balance entre rendimiento y eficiencia computacional. **MLflow** facilita el monitoreo del entrenamiento y la visualizaciÃ³n de mÃ©tricas para detectar problemas como el sobreajuste.

Este proyecto combina herramientas modernas con un enfoque prÃ¡ctico para abordar un problema real.

---

## ğŸ¯ Objetivos

1ï¸âƒ£ **Entrenar** un modelo de clasificaciÃ³n de texto utilizando **AG News** y **TinyBERT**.
2ï¸âƒ£ **Monitorear** el entrenamiento mediante grÃ¡ficas de la funciÃ³n de costo y mÃ©tricas de desempeÃ±o para training y validaciÃ³n.
3ï¸âƒ£ **Evaluar** el rendimiento del modelo con mÃ©tricas especÃ­ficas.
4ï¸âƒ£ **Utilizar MLflow** para registrar y visualizar los resultados del experimento, facilitando su interpretaciÃ³n.
5ï¸âƒ£ **Presentar un informe** con el proceso, los resultados y conclusiones obtenidas.

---

## ğŸ“‚ Dataset: AG News

El dataset **AG News** contiene noticias categorizadas en cuatro clases:

- ğŸŒ **Mundo** (Clase 0)
- ğŸ† **Deportes** (Clase 1)
- ğŸ’° **Negocios** (Clase 2)
- ğŸ”¬ **Ciencia/TecnologÃ­a** (Clase 3)

Cada instancia consta de un tÃ­tulo y una descripciÃ³n de la noticia, junto con su etiqueta correspondiente. Se ha reducido el tamaÃ±o a **1000 muestras para entrenamiento** y **500 para test**, con el fin de agilizar el proceso.

---

## ğŸ¤– Modelo: TinyBERT

Se ha seleccionado **TinyBERT**, una versiÃ³n optimizada de BERT, que conserva su arquitectura pero con menos parÃ¡metros, logrando eficiencia en tiempo y recursos computacionales.

---

## ğŸš€ Proceso de Entrenamiento

ğŸ”¹ **TokenizaciÃ³n**: Se usa el tokenizador de **TinyBERT**, con un lÃ­mite de **128 tokens**.
ğŸ”¹ **Entrenamiento**: Configurado en **2 Ã©pocas**, con batch size **4** para entrenamiento y **8** para validaciÃ³n.
ğŸ”¹ **MÃ©tricas**: Se calculan dentro del cÃ³digo mÃ©tricas como **accuracy, F1-score, precision y recall**.

---

## ğŸ“Š Visualizaciones con MLflow

El proyecto utiliza **MLflow** para registrar y visualizar mÃ©tricas clave:

1ï¸âƒ£ **ğŸ“ˆ EvoluciÃ³n de la Accuracy**
   ![Accuracy Evolution](Proyecto_ml/graficas/accuracy_evolution.png)
   - La precisiÃ³n mejora con las Ã©pocas, pasando de 0.68 en la primera a 0.82 en la segunda.
   - Indica que el modelo ha convergido correctamente.

2ï¸âƒ£ **ğŸ“Š EvoluciÃ³n de Accuracy y F1-Score**
   ![Metrics Evolution](Proyecto_ml/graficas/all_metrics_evolution.png)
   - Ambas mÃ©tricas han aumentado progresivamente, lo que indica una mejora consistente del modelo.
   - F1-score muestra balance entre precisiÃ³n y recall.

3ï¸âƒ£ **ğŸ¯ Matriz de ConfusiÃ³n**
   ![Confusion Matrix](Proyecto_ml/graficas/confusion_matrix.png)
   - Predicciones correctas e incorrectas del modelo.
   - Se observan errores en clases similares, como "Business" y "Sci/Tech".

4ï¸âƒ£ **ğŸ“Š EvoluciÃ³n del F1-Score**
   ![F1 Evolution](Proyecto_ml/graficas/f1_evolution.png)
   - Muestra un aumento en F1-score, indicando una mejora en el equilibrio entre precisiÃ³n y recall.

5ï¸âƒ£ **ğŸ† MÃ©tricas Finales**
   ![Final Metrics](Proyecto_ml/graficas/final_metrics.png)
   - **Loss**: 0.6916, indicando un error bajo.
   - **Accuracy**: 0.82, reflejando buen desempeÃ±o.
   - **F1-Score**: 0.8194, alineado con la accuracy.
   - **PrecisiÃ³n y Recall**: 0.8233 y 0.82 respectivamente, sin sesgo hacia falsos positivos o negativos.

6ï¸âƒ£ **ğŸ“‰ FunciÃ³n de Costo**
   ![Loss Function](Proyecto_ml/graficas/loss_function.png)
   - La funciÃ³n de pÃ©rdida disminuye con las Ã©pocas, mostrando aprendizaje estable.
   - No hay indicios de sobreajuste.

---
## MLflow desde local

1ï¸âƒ£ **Metricas del Modelo 1**
![pantallazo1](Proyecto_ml/images/pantallazo1.png)

2ï¸âƒ£ **Metricas del Modelo 2**
![pantallazo2](Proyecto_ml/images/pantallazo2.png)

3ï¸âƒ£ **Metricas del Modelo 3**
![pantallazo3](Proyecto_ml/images/pantallazo3.png)

4ï¸âƒ£ **Metricas del Modelo 4**
![pantallazo4](Proyecto_ml/images/pantallazo4.png)

5ï¸âƒ£ **Overview**
![pantallazo5](Proyecto_ml/images/pantallazo5.png)

6ï¸âƒ£ **Artifacts**
![pantallazo6](Proyecto_ml/images/pantallazo6.png)

---
## ğŸ“¦ Requisitos

```bash
torch
transformers
datasets
scikit-learn
matplotlib
numpy
mlflow
seaborn
```

---

## ğŸ›  InstalaciÃ³n

1ï¸âƒ£ Clona el repositorio:
   ```bash
   git clone https://github.com/yourusername/Proyecto_MLFlow.git
   cd Proyecto_MLFlow
   ```

2ï¸âƒ£ Instala las dependencias:
   ```bash
   pip install torch transformers datasets scikit-learn matplotlib numpy mlflow seaborn
   ```

---

## ğŸ— Estructura del Proyecto

```
ProjectoMLFlow/
â”‚
â”œâ”€â”€ ğŸ“œ ModeloMLFlow.py         # Script principal con el cÃ³digo de entrenamiento
â”œâ”€â”€ ğŸ“‚ modelo_final/           # Modelo entrenado
â”œâ”€â”€ ğŸ“‚ results/                # Resultados del entrenamiento
â”œâ”€â”€ ğŸ“‚ graficas/               # GrÃ¡ficas generadas
â”œâ”€â”€ ğŸ“‚ logs/                   # Logs del entrenamiento
â””â”€â”€ ğŸ“œ README.md               # Este archivo
```

---

## ğŸ” ConclusiÃ³n General

ğŸ”¹ **Resultados Ã³ptimos** en el entrenamiento, a pesar de limitaciones computacionales.
ğŸ”¹ **Aprendizaje positivo** reflejado en mejoras de **accuracy** y **F1-Score**.
ğŸ”¹ **ConfusiÃ³n en algunas clases** que puede mejorar con mÃ¡s datos y ajustes en hiperparÃ¡metros.
ğŸ”¹ **Tendencia decreciente en la funciÃ³n de pÃ©rdida**, sugiriendo un buen aprendizaje.

---

## âš ï¸ Limitaciones

âš ï¸ Uso de un dataset reducido para optimizar tiempos de entrenamiento.
âš ï¸ Algunas clases pueden requerir mayor ajuste en hiperparÃ¡metros.
âš ï¸ Para grandes modelos, puede requerirse **mÃ¡s recursos computacionales**.

---


