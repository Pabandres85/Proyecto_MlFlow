# Especializacion en IA UAO

## Grupo 3

## Integrantes: 

- Pablo Andr√©s Mu√±oz Mart√≠nez  -   **C√≥digo**: 2244676

- Leidy Yasmin Hoyos Parra - **C√≥digo**: 2245224 
                
- Johan David Mendoza Vargas  - **C√≥digo**: 2245019
                
- Yineth Tatiana Hern√°ndez Narvaez  -  **C√≥digo**: 2244789 
                
---

# üìå Proyecto de Monitoreo en ML - IA con TinyBERT, BERT-Mini y DistilBERT con MLflow

Este proyecto implementa un modelo de clasificaci√≥n de texto utilizando **TinyBERT**, **BERT-Mini** y **DistilBERT**, con seguimiento completo de m√©tricas y visualizaciones mediante **MLflow**.

---

## üìñ Introducci√≥n

Este proyecto utiliza modelos de la familia BERT para clasificar textos del dataset **AG News** en cuatro categor√≠as. Durante el entrenamiento, se monitorea el rendimiento mediante m√©tricas clave como **accuracy, F1-score, precision y recall**, adem√°s de generar visualizaciones para facilitar el an√°lisis de resultados.

El objetivo es comparar el rendimiento de estos modelos y determinar cu√°l ofrece la mejor precisi√≥n y generalizaci√≥n.

---

## üéØ Justificaci√≥n

La clasificaci√≥n de texto es esencial en aplicaciones como la organizaci√≥n autom√°tica de noticias. Se ha elegido **AG News** por su relevancia y tama√±o, mientras que los modelos de la familia **BERT** permiten balancear rendimiento y eficiencia computacional. **MLflow** facilita el monitoreo del entrenamiento y la visualizaci√≥n de m√©tricas para detectar problemas como el sobreajuste.

---

## üéØ Objetivos

1Ô∏è‚É£ **Entrenar** y comparar **TinyBERT**, **BERT-Mini** y **DistilBERT** en la tarea de clasificaci√≥n de texto.  

2Ô∏è‚É£ **Monitorear** el entrenamiento mediante gr√°ficas de la funci√≥n de costo y m√©tricas de desempe√±o.  

3Ô∏è‚É£ **Evaluar** el rendimiento de cada modelo con m√©tricas espec√≠ficas.  

4Ô∏è‚É£ **Utilizar MLflow** para registrar y visualizar los resultados del experimento.  

5Ô∏è‚É£ **Presentar un an√°lisis comparativo** de los modelos.  

---

## üìÇ Dataset: AG News

El dataset **AG News** contiene noticias categorizadas en cuatro clases:

- üåç **Mundo** (Clase 0)
- üèÜ **Deportes** (Clase 1)
- üí∞ **Negocios** (Clase 2)
- üî¨ **Ciencia/Tecnolog√≠a** (Clase 3)

Cada instancia consta de un t√≠tulo y una descripci√≥n de la noticia, junto con su etiqueta correspondiente. Se ha reducido el tama√±o a **1000 muestras para entrenamiento** y **500 para test**.

---

## ü§ñ Modelos

Se entrenaron y compararon los siguientes modelos:

- **TinyBERT** üèãÔ∏è‚Äç‚ôÇÔ∏è: Versi√≥n compacta y eficiente de BERT.

- **BERT-Mini** üìè: Un modelo con una estructura reducida de BERT.

- **DistilBERT** üöÄ: Modelo liviano que retiene el 97% del rendimiento de BERT con solo el 60% de los par√°metros.

---

## üìä An√°lisis de Cada Modelo

### **TinyBERT**

#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy TinyBERT](Proyecto_ml/graficas/tinybert_accuracy_evolution.png)

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n TinyBERT](Proyecto_ml/graficas/tinybert_confusion_matrix.png)

#### **Evoluci√≥n de F1-Score**
![F1-Score TinyBERT](Proyecto_ml/graficas/tinybert_f1_evolution.png)

#### **Funci√≥n de Costo**
![P√©rdida TinyBERT](Proyecto_ml/graficas/tinybert_loss_function.png)

---

### **BERT-Mini**

#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy BERT-Mini](Proyecto_ml/graficas/bert_mini_accuracy_evolution.png)

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n BERT-Mini](Proyecto_ml/graficas/bert_mini_confusion_matrix.png)

#### **Evoluci√≥n de F1-Score**
![F1-Score BERT-Mini](Proyecto_ml/graficas/bert_mini_f1_evolution.png)

#### **Funci√≥n de Costo**
![P√©rdida BERT-Mini](Proyecto_ml/graficas/bert_mini_loss_function.png)

---

### **DistilBERT**

#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy DistilBERT](Proyecto_ml/graficas/distilbert_accuracy_evolution.png)

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n DistilBERT](Proyecto_ml/graficas/distilbert_confusion_matrix.png)

#### **Evoluci√≥n de F1-Score**
![F1-Score DistilBERT](Proyecto_ml/graficas/distilbert_f1_evolution.png)

#### **Funci√≥n de Costo**
![P√©rdida DistilBERT](Proyecto_ml/graficas/distilbert_loss_function.png)

---

## üìä Comparaci√≥n de Modelos

### **1Ô∏è‚É£ Comparaci√≥n de Accuracy entre Modelos**
![Comparaci√≥n de Accuracy](Proyecto_ml/graficas/comparison_accuracy.png)

### **2Ô∏è‚É£ Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy](Proyecto_ml/graficas/comparison_accuracy_evolution.png)

### **3Ô∏è‚É£ Comparaci√≥n de Todas las M√©tricas**
![Comparaci√≥n de M√©tricas](Proyecto_ml/graficas/comparison_all_metrics.png)

### **4Ô∏è‚É£ Comparaci√≥n de F1-Score**
![Comparaci√≥n de F1-Score](Proyecto_ml/graficas/comparison_f1.png)

### **5Ô∏è‚É£ Gr√°fico Radar ‚Äì Comparaci√≥n Completa**
![Gr√°fico Radar](Proyecto_ml/graficas/comparison_radar.png)

---

## üèÜ **Conclusi√≥n Final**

1Ô∏è‚É£ **DistilBERT es el mejor modelo**, con **mayor precisi√≥n, mejor estabilidad y menor confusi√≥n**. 

2Ô∏è‚É£ **BERT-Mini es una alternativa intermedia**, con buen rendimiento pero menor que DistilBERT.  

3Ô∏è‚É£ **TinyBERT es el menos eficiente**, con **m√°s errores de clasificaci√≥n y menor precisi√≥n**.  

---

## üì¶ Requisitos

```bash
torch
transformers
datasets
scikit-learn
matplotlib
numpy
mlflow
seaborn
```

---

## üõ† Instalaci√≥n

1Ô∏è‚É£ Clona el repositorio:
   ```bash
   git clone https://github.com/yourusername/Proyecto_MLFlow.git
   cd Proyecto_MLFlow
   ```

2Ô∏è‚É£ Instala las dependencias:
   ```bash
   pip install torch transformers datasets scikit-learn matplotlib numpy mlflow seaborn
   ```
---

## ‚ö†Ô∏è Limitaciones

‚ö†Ô∏è Uso de un dataset reducido para optimizar tiempos de entrenamiento.
‚ö†Ô∏è Algunas clases pueden requerir mayor ajuste en hiperpar√°metros.
‚ö†Ô∏è Para grandes modelos, puede requerirse **m√°s recursos computacionales**.

---


