# Especializacion en IA UAO

## Grupo 3

## Integrantes: 

- Pablo Andr√©s Mu√±oz Mart√≠nez  -   **C√≥digo**: 2244676

- Leidy Yasmin Hoyos Parra - **C√≥digo**: 2245224 
                
- Johan David Mendoza Vargas  - **C√≥digo**: 2245019
                
- Yineth Tatiana Hern√°ndez Narvaez  -  **C√≥digo**: 2244789 
                
---

# üìå Proyecto de Monitoreo en ML - IA con TinyBERT, BERT-Mini y DistilBERT con MLflow

Este proyecto implementa un modelo de clasificaci√≥n de texto utilizando **TinyBERT**, **BERT-Mini** y **DistilBERT**, con seguimiento completo de m√©tricas y visualizaciones mediante **MLflow**.

---

## üìñ Introducci√≥n

Este proyecto utiliza modelos de la familia BERT para clasificar textos del dataset **AG News** en cuatro categor√≠as. Durante el entrenamiento, se monitorea el rendimiento mediante m√©tricas clave como **accuracy, F1-score, precision y recall**, adem√°s de generar visualizaciones para facilitar el an√°lisis de resultados.

El objetivo es comparar el rendimiento de estos modelos y determinar cu√°l ofrece la mejor precisi√≥n y generalizaci√≥n.

---

## üéØ Justificaci√≥n

La clasificaci√≥n de texto es esencial en aplicaciones como la organizaci√≥n autom√°tica de noticias. Se ha elegido **AG News** por su relevancia y tama√±o, mientras que los modelos de la familia **BERT** permiten balancear rendimiento y eficiencia computacional. **MLflow** facilita el monitoreo del entrenamiento y la visualizaci√≥n de m√©tricas para detectar problemas como el sobreajuste.

---

## üéØ Objetivos

1Ô∏è‚É£ **Entrenar** y comparar **TinyBERT**, **BERT-Mini** y **DistilBERT** en la tarea de clasificaci√≥n de texto.  

2Ô∏è‚É£ **Monitorear** el entrenamiento mediante gr√°ficas de la funci√≥n de costo y m√©tricas de desempe√±o.  

3Ô∏è‚É£ **Evaluar** el rendimiento de cada modelo con m√©tricas espec√≠ficas.  

4Ô∏è‚É£ **Utilizar MLflow** para registrar y visualizar los resultados del experimento.  

5Ô∏è‚É£ **Presentar un an√°lisis comparativo** de los modelos.  

---

## üìÇ Dataset: AG News

El dataset **AG News** contiene noticias categorizadas en cuatro clases:

- üåç **Mundo** (Clase 0)
- üèÜ **Deportes** (Clase 1)
- üí∞ **Negocios** (Clase 2)
- üî¨ **Ciencia/Tecnolog√≠a** (Clase 3)

Cada instancia consta de un t√≠tulo y una descripci√≥n de la noticia, junto con su etiqueta correspondiente. Se ha reducido el tama√±o a **1000 muestras para entrenamiento** y **500 para test**.

---

## ü§ñ Modelos

Se entrenaron y compararon los siguientes modelos:

- **TinyBERT** üèãÔ∏è‚Äç‚ôÇÔ∏è: Versi√≥n compacta y eficiente de BERT.

- **BERT-Mini** üìè: Un modelo con una estructura reducida de BERT.

- **DistilBERT** üöÄ: Modelo liviano que retiene el 97% del rendimiento de BERT con solo el 60% de los par√°metros.

---
## MLflow desde local

1Ô∏è‚É£ **Metricas del Modelo 1**

![pantallazo1](Proyecto_ml/images/pantallazo1.png)


2Ô∏è‚É£ **Metricas del Modelo 2**

![pantallazo2](Proyecto_ml/images/pantallazo2.png)


3Ô∏è‚É£ **Metricas del Modelo 3**

![pantallazo3](Proyecto_ml/images/pantallazo3.png)


4Ô∏è‚É£ **Metricas del Modelo 4**

![pantallazo4](Proyecto_ml/images/pantallazo4.png)


5Ô∏è‚É£ **Overview**

![pantallazo5](Proyecto_ml/images/pantallazo5.png)


6Ô∏è‚É£ **Artifacts**

![pantallazo6](Proyecto_ml/images/pantallazo6.png)

---

## üìä An√°lisis de Cada Modelo

### **TinyBERT**
#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy TinyBERT](Proyecto_ml/graficas/tinybert_accuracy_evolution.png)
- El modelo **mejor√≥ su accuracy** desde 0.715 hasta 0.825 en dos √©pocas.
- Su crecimiento es estable, pero se mantiene **por debajo de los otros modelos**.

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n TinyBERT](Proyecto_ml/graficas/tinybert_confusion_matrix.png)
- **M√°s confusi√≥n** en las clases **Business y Sci/Tech**, lo que indica dificultades en la separaci√≥n de categor√≠as similares.

#### **Evoluci√≥n de F1-Score**
![F1-Score TinyBERT](Proyecto_ml/graficas/tinybert_f1_evolution.png)
- Su **F1-score final es 0.8247**, el m√°s bajo de los tres modelos.

#### **Funci√≥n de Costo**
![P√©rdida TinyBERT](Proyecto_ml/graficas/tinybert_loss_function.png)
- **Disminuci√≥n progresiva**, pero su p√©rdida inicial es mayor, indicando menor eficiencia en aprendizaje.

---

### **BERT-Mini**
#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy BERT-Mini](Proyecto_ml/graficas/bert_mini_accuracy_evolution.png)
- Accuracy final **0.832**, mejor que TinyBERT pero inferior a DistilBERT.

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n BERT-Mini](Proyecto_ml/graficas/bert_mini_confusion_matrix.png)
- **Menos confusi√≥n** que TinyBERT, pero sigue habiendo errores entre **Business y Sci/Tech**.

#### **Evoluci√≥n de F1-Score**
![F1-Score BERT-Mini](Proyecto_ml/graficas/bert_mini_f1_evolution.png)
- Su **F1-score es 0.8311**, ligeramente mejor que TinyBERT.

#### **Funci√≥n de Costo**
![P√©rdida BERT-Mini](Proyecto_ml/graficas/bert_mini_loss_function.png)
- **Mejor reducci√≥n de p√©rdida** en comparaci√≥n con TinyBERT.

---

### **DistilBERT**
#### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy DistilBERT](Proyecto_ml/graficas/distilbert_accuracy_evolution.png)
- **Accuracy m√°s alta** con **0.866**, mostrando la mejor estabilidad.

#### **Matriz de Confusi√≥n**
![Matriz de Confusi√≥n DistilBERT](Proyecto_ml/graficas/distilbert_confusion_matrix.png)
- **Menor confusi√≥n entre clases**, indicando mejor generalizaci√≥n.

#### **Evoluci√≥n de F1-Score**
![F1-Score DistilBERT](Proyecto_ml/graficas/distilbert_f1_evolution.png)
- **Mejor balance entre precisi√≥n y recall**, con un **F1-score de 0.8653**.

#### **Funci√≥n de Costo**
![P√©rdida DistilBERT](Proyecto_ml/graficas/distilbert_loss_function.png)
- **Menor p√©rdida y mejor convergencia** en comparaci√≥n con los otros modelos.

---

## üìä Comparaci√≥n de Modelos

### **Comparaci√≥n de Accuracy entre Modelos**
![Comparaci√≥n de Accuracy](Proyecto_ml/graficas/comparison_accuracy.png)
- **DistilBERT supera a los dem√°s** con **0.866**.

### **Evoluci√≥n de Accuracy**
![Evoluci√≥n de Accuracy](Proyecto_ml/graficas/comparison_accuracy_evolution.png)
- **DistilBERT tiene la curva m√°s estable**, con mejor precisi√≥n desde el inicio.

### **Comparaci√≥n de Todas las M√©tricas**
![Comparaci√≥n de M√©tricas](Proyecto_ml/graficas/comparison_all_metrics.png)
- DistilBERT lidera en todas las m√©tricas, TinyBERT es el m√°s d√©bil.

### **Comparaci√≥n de F1-Score**
![Comparaci√≥n de F1-Score](Proyecto_ml/graficas/comparison_f1.png)
- **DistilBERT con el F1-score m√°s alto**, indicando mejor balance de clasificaci√≥n.

### **Gr√°fico Radar ‚Äì Comparaci√≥n Completa**
![Gr√°fico Radar](Proyecto_ml/graficas/comparison_radar.png)
- **DistilBERT domina todas las m√©tricas** y es el modelo m√°s robusto.

---

## üèÜ **Conclusi√≥n Final**
1Ô∏è‚É£ **DistilBERT es el mejor modelo**, con **mayor precisi√≥n y menor confusi√≥n**.  

2Ô∏è‚É£ **BERT-Mini es una alternativa intermedia**, con **buen rendimiento pero inferior a DistilBERT**.  

3Ô∏è‚É£ **TinyBERT es el menos eficiente**, con **m√°s errores de clasificaci√≥n y menor precisi√≥n**.  

---

## ‚ö†Ô∏è Limitaciones

‚ö†Ô∏è Uso de un dataset reducido para optimizar tiempos de entrenamiento.
‚ö†Ô∏è Algunas clases pueden requerir mayor ajuste en hiperpar√°metros.
‚ö†Ô∏è Para grandes modelos, puede requerirse **m√°s recursos computacionales**.

---


